{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mnist/train-images-idx3-ubyte.gz already exists\n",
      "data/mnist/train-labels-idx1-ubyte.gz already exists\n",
      "data/mnist/t10k-images-idx3-ubyte.gz already exists\n",
      "data/mnist/t10k-labels-idx1-ubyte.gz already exists\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter initialization and train_set size and \n",
    "# test set size\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "n_train = 60000\n",
    "n_test = 10000\n",
    "\n",
    "# Download the dataset and pre process it for training and testing\n",
    "mnist_folder = 'data/mnist'\n",
    "utils.download_mnist(mnist_folder)\n",
    "train, val, test = utils.read_mnist(mnist_folder, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets and the iterators\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "train_data = train_data.shuffle(10000)\n",
    "train_data = train_data.batch(batch_size) # Create batches of 128 examples \n",
    "\n",
    "# Training dataset\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test)\n",
    "test_data = test_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create one iterator and initialize it with different datasets\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types,\n",
    "                                          train_data.output_shapes)\n",
    "\n",
    "img, label = iterator.get_next()\n",
    "\n",
    "train_init = iterator.make_initializer(train_data)\n",
    "test_init = iterator.make_initializer(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weights and bias\n",
    "w = tf.get_variable(initializer=tf.random_normal_initializer(0, 0.01), shape=(784, 10), name='weights')\n",
    "b = tf.get_variable(initializer=tf.zeros_initializer(), shape=(1, 10), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.matmul(img, w) + b\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label, name='entropy')\n",
    "loss = tf.reduce_mean(entropy, name='loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs/logreg', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0 0.3630769000843514\n",
      "Average loss epoch 1 0.29272632980069446\n",
      "Average loss epoch 2 0.2810420200228691\n",
      "Average loss epoch 3 0.2769210001583709\n",
      "Average loss epoch 4 0.27500324777738994\n",
      "Average loss epoch 5 0.27007326097335926\n",
      "Average loss epoch 6 0.2685691674088323\n",
      "Average loss epoch 7 0.2663046835640142\n",
      "Average loss epoch 8 0.26622128384404403\n",
      "Average loss epoch 9 0.2659454184042853\n",
      "Average loss epoch 10 0.2627765771088212\n",
      "Average loss epoch 11 0.26139979771403377\n",
      "Average loss epoch 12 0.26058941441912986\n",
      "Average loss epoch 13 0.26055967168405997\n",
      "Average loss epoch 14 0.2585872258904368\n",
      "Average loss epoch 15 0.2593832071437392\n",
      "Average loss epoch 16 0.25791870889275575\n",
      "Average loss epoch 17 0.2540261521935463\n",
      "Average loss epoch 18 0.25339071100880933\n",
      "Average loss epoch 19 0.2543319433407728\n",
      "Average loss epoch 20 0.2535630573366964\n",
      "Average loss epoch 21 0.2586546514616456\n",
      "Average loss epoch 22 0.2530089950145677\n",
      "Average loss epoch 23 0.25335650197988335\n",
      "Average loss epoch 24 0.25376283569737923\n",
      "Average loss epoch 25 0.25194407415597936\n",
      "Average loss epoch 26 0.2539066703340342\n",
      "Average loss epoch 27 0.2504241145627443\n",
      "Average loss epoch 28 0.25341734099526736\n",
      "Average loss epoch 29 0.2511674051887767\n",
      "Total Time: 13.9219810962677 seconds\n",
      "Accuracy 0.9024\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        sess.run(train_init)\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "    \n",
    "        try:\n",
    "            while True:\n",
    "                _, l = sess.run([optimizer, loss])\n",
    "                total_loss += l\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "        print('Average loss epoch {0} {1}'.format(i, total_loss/n_batches))\n",
    "        \n",
    "    print('Total Time: {0} seconds'.format(time.time() - start_time))\n",
    "    \n",
    "    sess.run(test_init)\n",
    "    total_correct_preds = 0\n",
    "    try:\n",
    "        while True:\n",
    "            accuracy_batch = sess.run(accuracy)\n",
    "            total_correct_preds += accuracy_batch\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    \n",
    "    print('Accuracy {0}'.format(total_correct_preds/n_test))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
