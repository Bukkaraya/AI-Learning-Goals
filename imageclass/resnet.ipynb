{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns a Conv Layer with \n",
    "# Kernel Size 3x3\n",
    "# Stride Size of stride x stride (default = 1)\n",
    "# Padding Size of 1x1\n",
    "# Convolution takes in nc_in planes and gives an output of nc_out planes\n",
    "def sameConv(nc_in, nc_out, stride=1):\n",
    "    return nn.Conv2d(nc_in, nc_out, kernel_size=3, stride=stride, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Basic Resnet Block with no BottleNeck used for smaller Resnet implementations\n",
    "# Like ResNet18 and ResNet34\n",
    "# The idea is that the n + 2 layer returns an activation of H(x) = g(F(x) + x)\n",
    "# Instead of parameters that are randomly initialized we have an identity mapping\n",
    "# This makes it much easier for the network to learn since it does not have to learn parameters\n",
    "# from the scratch\n",
    "class BasicResBlock(nn.Module):\n",
    "    def __init__(self, nc_in, nc_out, stride=1):\n",
    "        super(BasicResBlock, self).__init__()\n",
    "        self.conv1 = sameConv(nc_in, nc_out)\n",
    "        self.bn1 = nn.BatchNorm2d(nc_out)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = sameConv(nc_out, nc_out)\n",
    "        self.bn2 = nn.BatchNorm2d(nc_out)\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        activation = self.conv1(x)\n",
    "        activation = self.bn1(x)\n",
    "        activation = self.relu(x)\n",
    "        activation = self.conv2(x)\n",
    "        activation = self.bn2(x)\n",
    "        activation += residual\n",
    "        \n",
    "        activation = self.relu(activation)\n",
    "        \n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        #7x7 Convolution with Stride 2 and padding for 3\n",
    "        #Followed by a batch normalization and max pooling\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Make the resnet layers\n",
    "        # The first layer is layers[0] number of ResidualBlocks with plane size of 64\n",
    "        # The second layer is layers[1] number of ResidualBlocks with plane size of 128\n",
    "        # The third layer is layers[2] number of ResidualBlocks with plane size of 256\n",
    "        # The fourth layer is layers[3] number of ResidualBlocks with plane size of 512\n",
    "        # The basic rule of ResNet is that everytime we decrease the the input size with\n",
    "        # with a convolution we double the number of channels/planes\n",
    "        self.layer1 = _make_resnet_layer(block, 64, layers[0])\n",
    "        self.layer2 = _make_resnet_layer(block, 128, layers[1])\n",
    "        self.layer3 = _make_resnet_layer(block, 256, layers[2])\n",
    "        self.layer4 = _make_resnet_layer(block, 512, layers[3])\n",
    "        \n",
    "        #Average Pooling and then fully connected layer\n",
    "        self.avgpool = AvgPool2d(7, stride=1)\n",
    "        \n",
    "        # A fully connected layer with 512 * block.expansion number of inputs\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        #Need to figure out what this is doing\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n - m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "    #Function that makes a layer of ResNet Blocks with \n",
    "    def _make_resnet_layer(self, block, nc_out, blocks, stride=1):\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(block(self.inplanes, planes, stride, None))\n",
    "        self.inplanes = planes * block.explansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, nc_out))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "    \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
